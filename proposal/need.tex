
Before I describe how I plan to optimize Curry, I need to answer a fundamental question.
Why bother?
Is there a real need for optimizing Curry?
There are currently three Curry compilers that have their own strategy for optimization.
Pakcs compiles Curry to Prolog, and relies on the Prolog interpreter to optimize the logic programming code.
The Kics2 compiler compiles Curry to Haskell, and relies on GHC to optimize the code.
Finally, Sprite compiles Curry to LLVM, and uses LLVM to optimize the low level code.
Each of these compilers has a significant disadvantage that could be solved by optimization.

Let's consider the Pakcs compiler.
Pakcs will compile each Curry function into a set of Prolog clauses.
This may seem like a problem, since Prolog doesn't have a concept of functions,
but it turns out we can emulate a function very easily in Prolog.
The trick is to add another parameter to the clause to represent the return value.
I'll use the Curry function for adding all of the values in a list.

\begin{verbatim}
sum [] = 0
sum (x:xs) = x + sum xs
\end{verbatim}

Let's translate this to Prolog.
In Prolog, a clause doesn't return a value.
It just finds values for variables such that the clause is true.
So, our clause is a relation between a list and it's sum.
\begin{verbatim}
sum(List, N)
\end{verbatim}
we want to find a value for \texttt{N} such that this relation holds.
We can do this with a recursive relation:
\begin{verbatim}
sum([],     0).
sum([X|XS], N) :- sum(XS,M), N is X+M.
\end{verbatim}

This is nice and simple, unfortunately a Curry compiler can't use this translation
because of lazy evaluation.
Conside the \texttt{map} function:
\begin{verbatim}
map f [] = []
map f (x:xs) = f x : map f xs
\end{verbatim}
Assuming we have an \texttt{apply} predicate that will apply a function to it's argument,
this would be translated as:
\begin{verbatim}
map(F, [],     []).
map(F, [X|XS], [FX|FXS]) :- apply(F,X,FX), map(F,XS,FXS).
\end{verbatim}

Since we must apply \texttt F to \texttt X for this predicate, we will perform eager evaluation.
All of the values of the list will be fully evaluated.
To get around this problem, we must create a new type of node that is an unevaluated function application.
\texttt{apply\_F(F,X)}.
This is similar to a thunk in Haskell.
I'll use \texttt{func\_F} to represent an unevaluated application of \texttt{func}.
Now map will actually be translated to:
\begin{verbatim}
map(F, [],     []).
map(F, [X|XS], [apply_F(F,X) | apply_F(apply_F(map,F), XS)]).
\end{verbatim}

Here we reconstructed the list, and created four new nodes, a new list, and three application nodes.
This seems inefficient, but this process of rewiring graphs is very common in lazy languages.
However, this has a negative effect on our \texttt{sum} example.
This example must be translated to:
\begin{verbatim}
sum([],     0).
sum([X|XS], apply_F(apply_F(+_F, X), apply_F(sum_F, XS)).
\end{verbatim}
We created three new nodes where the original translation didn't need any new nodes.

Creating new nodes is a problem, however this is not new.
Haskell compilers have dealt with this issue for years, and they have several solutions.
This leads to a new question.
Could we compile Curry to Haskell and use a Haskell compiler to optimize the code?
This is the idea behind the Kics2 compiler.
This is a good idea in theory, but it has one major drawback.
In order to compile Curry to Haskell we need to handle non-determinism in Haskell.
This is not as straight forward as we might hope.
A current approach is known as pull tabbing \cite{Antoy11ICLP}.
This strategy will be defined later, but it requires that every variable contains a unique identifier,
and that we keep record of all of the non-deterministic choices that have been made.

The goal of the Kics2 compiler is that deterministic Curry functions are translated into simple Haskell functions
that may contains a few extra parameters.
Non-deterministic function may require more care.
However, there are a few immediate consequences.
If Kics2 cannot determine if a function is deterministic, then it must assume that it is not.
Furthermore, Kics2 cannot inline any non-deterministic function.
This is a problem because non-deterministic functions are significantly more expensive than deterministic functions.

This is unfortunate, but it is not entirely surprising.
However, there are more severe consequences for compiling to Haskell.
GHC will often fail to optimize deterministic functions.
As an example consider the simple non-deterministic expression:
\begin{verbatim}
e = (1 + 2 + 3 + 4 + 5) `div` (1 ? 0)
\end{verbatim}
It's clear that this expression only has one value.  The expression \texttt{1 + 2 + 3 + 4 + 5 `div` 0} will fail.
So, we should be able to optimize this to \texttt{15}.
Unfortunately Kics2 is not able to optimize this, because GHC doesn't know what the \texttt ? function is.
Furthermore, it doesn't know how to optimize failure.
This is expected, but we might expect GHC to be able to optimize the subexpression \texttt{1 + 2 + 3 + 4 + 5}.
This is a simple case of constant folding.

In order to determine Kics2's ability to optimize Curry, it is necessary to look at the generated code.
The Haskell code is not encouraging.

\begin{verbatim}
nd_C_test :: IDSupply -> Cover -> ConstStore -> Curry_Prelude.C_Int
nd_C_test s cd cs = let s0 = s
  in s0 `seq` Curry_Prelude.d_C_div (Curry_Prelude.d_OP_plus
  (Curry_Prelude.d_OP_plus (Curry_Prelude.d_OP_plus 
  (Curry_Prelude.d_OP_plus (Curry_Prelude.C_Int 1#)
  (Curry_Prelude.C_Int 2#) cd cs) (Curry_Prelude.C_Int 3#) cd cs) 
  (Curry_Prelude.C_Int 4#) cd cs) (Curry_Prelude.C_Int 5#) cd cs) 
  (Curry_Prelude.nd_OP_qmark (Curry_Prelude.C_Int 0#) 
  (Curry_Prelude.C_Int 1#) s0 cd cs) cd cs
\end{verbatim}

This includes a lot of name mangling, which isn't surprising.
However, what is surprising is the introduction of the \texttt{C\_Int} constructor.
We would hope that \texttt{d\_OP\_plus} and \texttt{C\_Int} 
are wrappers for Haskell's \texttt{+} and \texttt{Int} respectively.
Taking a look at the generated assembly code quickly confirms that this is not the case.
In fact, GHC must construct a closure for each argument of each function, and it is not able to optimize anything in this expression.

At this point, it's reasonable to write this off as a bad example.  Clearly no one would want to write this code.
Even if they did, they could write it in a much more Haskell-friendly way.

\begin{verbatim}
fifteen = (1 + 2 + 3 + 4 + 5)
e = fifteen `div` (1 ? 0)
\end{verbatim}

This is arguably better code than the first example, and GHC should be able to optimize \texttt{fifteen}.
At this point it shouldn't be surprising that GHC fails the code generated by Kics2.
The generated assembly code is actually very similar to the first example, except that \texttt{fifteen}
is given it's own closure.
So, why can't GHC optimize either of these two examples?
The problem is simple.  \texttt{C\_Int} isn't \texttt{Int}, and \texttt{d\_OP\_plus} isn't \texttt{+}.
The GHC optimizer has no idea that these are constant arithmetic values, so it
cannot assume that it can apply constant folding.
We might hope that unboxing and inlining would be enough to get out expression into a form
that GHC can optimize, but the \texttt{Cover} and \texttt{ConstStore} arguments 
change the shape of the function so that GHC can't convert it to a form where constant folding would apply.
Even though the expresion \texttt{1 + 2 + 3 + 4 + 5} is entirely deterministic, it might exist
in a non-deterministic context.
Therefore kicks2 needs to keep track of information for pull-tabbing.

There are similar problems with function inlining, and partial evaluation.
However, I believe that this is the simplest example that demonstrates the problem.
These compilation strategies will have a difficult time optimizing many common Curry programs.
I believe that the best solution here is to build up the theory of optimization for functional logic programs.
Much of this theory will be similar to optimizing imperative, functional, and logic programs,
so it is worth taking a detour to explore the history of compiler optimizations.

